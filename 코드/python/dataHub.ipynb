{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import csv\n",
    "import psycopg2\n",
    "import datetime\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파일명에 '사용자정의채널'이 들어간 파일을 읽는다.\n",
    "\n",
    "# 2. 유효성 검사를 한다.\n",
    "\n",
    "# 3. 전처리를 한다.\n",
    "\n",
    "# 4. db에 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 광고 날짜를 check_date_list min max로.\n",
    "# 제트배송은 계정 구분이 불안함. 매번 확인해야 함.\n",
    "# try catch로 예외처리 하고, 어디서 에러가 났는지 콘솔에 출력하도록.\n",
    "# 메타 토큰이 만료가 되는 문제가 생길 수 있음.\n",
    "# 메타의 전환값을 제대로 파악해야 하는 문제가 있다.\n",
    "# excutemany가 더 좋은지 파악하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 날짜 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_date_list = ['2023-09-12']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버광고_계정1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['검색광고_운영관리팀,zero2one (98).csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 파일명이 '검색광고_운영관리팀,zero2one'으로 시작하는 파일을 읽는다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "네이버광고_계정1 = [file for file in file_list if file.startswith('검색광고_운영관리팀,zero2one')]\n",
    "\n",
    "네이버광고_계정1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유효성 검사 및 전처리 완료\n"
     ]
    }
   ],
   "source": [
    "# 2. 유효성 검사를 한다.\n",
    "# 3. 전처리를 한다.\n",
    "\n",
    "if  len(네이버광고_계정1) == 1:\n",
    "\n",
    "    df = pd.read_csv(root_path + '/' + 네이버광고_계정1[0], skiprows=1, thousands = ',')\n",
    "    df['날짜'] = df['일별'].apply(lambda x: x.replace('.', '-')[0:-1])\n",
    "    df['계정'] = 'zero2one' \n",
    "\n",
    "    날짜 = sorted(df['날짜'].unique().tolist())\n",
    "    \n",
    "    if 날짜 == sorted(check_date_list):\n",
    "        df.to_csv(root_path + '/dataSub/네이버광고_계정1/' + 네이버광고_계정1[0], encoding='cp949', index=False)\n",
    "        os.remove(root_path + '/' + 네이버광고_계정1[0])\n",
    "        print('유효성 검사 및 전처리 완료')\n",
    "\n",
    "    else:\n",
    "        print('실행안됨 : 날짜가 맞지 않습니다.')\n",
    "else:\n",
    "    print('실행안됨 : dataHub에 파일이 없습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/네이버광고_계정1/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == 1:\n",
    "    df = pd.read_csv(root_path + '/dataSub/네이버광고_계정1/' + preprocessed_file[0], encoding='cp949')\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"AD_Naver\" (\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"reg_date\", \"id\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "\n",
    "\n",
    "    shutil.move(root_path + '/dataSub/네이버광고_계정1/' + preprocessed_file[0], root_path + '/dataSub/네이버광고_계정1/DB입력완료/' + preprocessed_file[0][0:-4] + '_' + min(check_date_list) + '~' + max(check_date_list) + '.csv')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버광고_계정2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[zero2one2]검색광고_운영관리팀,zero2one2 (97).csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 파일명이 '[zero2one2]검색광고_운영관리팀,zero2one2'으로 시작하는 파일을 읽는다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "네이버광고_계정2 = [file for file in file_list if file.startswith('[zero2one2]검색광고_운영관리팀,zero2one2')]\n",
    "\n",
    "네이버광고_계정2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유효성 검사 및 전처리 완료\n"
     ]
    }
   ],
   "source": [
    "# 2. 유효성 검사를 한다.\n",
    "# 3. 전처리를 한다.\n",
    "\n",
    "if  len(네이버광고_계정2) == 1:\n",
    "\n",
    "    df = pd.read_csv(root_path + '/' + 네이버광고_계정2[0], skiprows=1, thousands = ',')\n",
    "    df['날짜'] = df['일별'].apply(lambda x: x.replace('.', '-')[0:-1])\n",
    "    df['계정'] = 'zero2one2'\n",
    "\n",
    "    날짜 = sorted(df['날짜'].unique().tolist())\n",
    "    \n",
    "    if 날짜 == sorted(check_date_list):\n",
    "        df.to_csv(root_path + '/dataSub/네이버광고_계정2/' + 네이버광고_계정2[0], encoding='cp949', index=False)\n",
    "        os.remove(root_path + '/' + 네이버광고_계정2[0])\n",
    "        print('유효성 검사 및 전처리 완료')\n",
    "\n",
    "    else:\n",
    "        print('실행안됨 : 날짜가 맞지 않습니다.')\n",
    "else:\n",
    "    print('실행안됨 : dataHub에 파일이 없습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/네이버광고_계정2/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == 1:\n",
    "    df = pd.read_csv(root_path + '/dataSub/네이버광고_계정2/' + preprocessed_file[0], encoding='cp949')\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"AD_Naver\" (\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"reg_date\", \"id\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "\n",
    "\n",
    "    shutil.move(root_path + '/dataSub/네이버광고_계정2/' + preprocessed_file[0], root_path + '/dataSub/네이버광고_계정2/DB입력완료/' + preprocessed_file[0][0:-4] + '_' + min(check_date_list) + '~' + max(check_date_list) + '.csv')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버광고_계정3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[zero2one3]일별광고보고서,zero2one3 (43).csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 파일명이 '[zero2one3]일별광고보고서,zero2one3'으로 시작하는 파일을 읽는다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "네이버광고_계정3 = [file for file in file_list if file.startswith('[zero2one3]일별광고보고서,zero2one3')]\n",
    "\n",
    "네이버광고_계정3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유효성 검사 및 전처리 완료\n"
     ]
    }
   ],
   "source": [
    "# 2. 유효성 검사를 한다.\n",
    "# 3. 전처리를 한다.\n",
    "\n",
    "if  len(네이버광고_계정3) == 1:\n",
    "\n",
    "    df = pd.read_csv(root_path + '/' + 네이버광고_계정3[0], skiprows=1, thousands = ',')\n",
    "    df['날짜'] = df['일별'].apply(lambda x: x.replace('.', '-')[0:-1])\n",
    "    df['계정'] = 'zero2one3'\n",
    "\n",
    "    날짜 = sorted(df['날짜'].unique().tolist())\n",
    "    \n",
    "    if 날짜 == sorted(check_date_list):\n",
    "        df.to_csv(root_path + '/dataSub/네이버광고_계정3/' + 네이버광고_계정3[0], encoding='cp949', index=False)\n",
    "        os.remove(root_path + '/' + 네이버광고_계정3[0])\n",
    "        print('유효성 검사 및 전처리 완료')\n",
    "\n",
    "    else:\n",
    "        print('실행안됨 : 날짜가 맞지 않습니다.')\n",
    "else:\n",
    "    print('실행안됨 : dataHub에 파일이 없습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/네이버광고_계정3/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == 1:\n",
    "    df = pd.read_csv(root_path + '/dataSub/네이버광고_계정3/' + preprocessed_file[0], encoding='cp949')\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"AD_Naver\" (\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"reg_date\", \"id\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "\n",
    "\n",
    "    shutil.move(root_path + '/dataSub/네이버광고_계정3/' + preprocessed_file[0], root_path + '/dataSub/네이버광고_계정3/DB입력완료/' + preprocessed_file[0][0:-4] + '_' + min(check_date_list) + '~' + max(check_date_list) + '.csv')\n",
    "\n",
    "else:\n",
    "    print('파일 : ' + str(preprocessed_file))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구글 애널리틱스 (구글애즈연동)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 정의\n",
    "def get_google_analytics_data(date):\n",
    "\n",
    "    # 서비스 계정 인증\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        'C:/phytoway_2/코드/python/데이터수집/datacollectautomation-04543e89aa13.json', scopes=['https://www.googleapis.com/auth/analytics.readonly'])\n",
    "\n",
    "    # Google Analytics Reporting API V4 빌드\n",
    "    analytics = build('analyticsreporting', 'v4', credentials=credentials)\n",
    "\n",
    "    # Google Analytics에서 데이터 조회를 위한 보고서 요청 생성\n",
    "    response = analytics.reports().batchGet(\n",
    "        body={\n",
    "            'reportRequests': [\n",
    "                {\n",
    "                    'viewId': '253559313', # 조회 대상 뷰 ID 입력\n",
    "                    'dateRanges': [{'startDate': date, 'endDate': date}], # 조회 기간 설정\n",
    "                    'metrics': [{'expression': 'ga:users'}, {'expression': 'ga:newUsers'}, {'expression': 'ga:sessions'}, {'expression': 'ga:bounceRate'}, {'expression': 'ga:pageviewsPerSession'}, {'expression': 'ga:avgSessionDuration'}, {'expression': 'ga:transactionsPerSession'}, {'expression': 'ga:transactions'}, {'expression': 'ga:transactionRevenue'}], # 조회할 지표 설정\n",
    "                    'dimensions': [{'name': 'ga:adGroup'}, {'name': 'ga:adwordsAdGroupID'}], # 조회할 차원 설정\n",
    "                    'pageSize': 5000, # 페이지당 결과 수 설정\n",
    "                    'samplingLevel': 'LARGE' # 샘플링 레벨 설정\n",
    "                }]\n",
    "        }\n",
    "    ).execute()\n",
    "\n",
    "\n",
    "\n",
    "    # Google Analytics 응답에서 데이터 추출\n",
    "    rows = response['reports'][0]['data']['rows']\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        dimensions = row['dimensions']\n",
    "        metrics = row['metrics'][0]['values']\n",
    "        data.append(dimensions + metrics)\n",
    "\n",
    "    # 추출된 데이터를 Pandas DataFrame으로 변환\n",
    "    df = pd.DataFrame(data, columns=['ga:adGroup', 'ga:adwordsAdGroupID', 'Users', 'newUsers', 'Sessions', 'bounceRate', 'pageviewsPerSession', 'avgSessionDuration', 'transactionsPerSession', 'transactions', 'transactionRevenue'])\n",
    "    df = df[(df['transactions'] > '0') & (df['ga:adwordsAdGroupID'] != '(not set)')]\n",
    "    df['reg_date'] = date\n",
    "    df['transactionRevenue'] = df['transactionRevenue'].apply(lambda x: int(float(x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 입력 완료\n"
     ]
    }
   ],
   "source": [
    "# api 호출 후 db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "for date in check_date_list:\n",
    "    df = get_google_analytics_data(date)\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"ad_ga_aw\" (\"adgroup\", \"adgroup_id\", \"user\", \"new_user\", \"session\", \"quit_rate\", \"page_per_session\", \"session_mean\", \"conversion\", \"order_cnt\", \"gross\", \"reg_date\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "    \n",
    "    print(date + ' 입력 완료')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자정의채널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파일명에 '사용자정의채널'이 들어간 파일을 읽는다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "사용자정의채널 = [file for file in file_list if '사용자정의채널' in file]\n",
    "\n",
    "사용자정의채널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 유효성 검사를 한다.\n",
    "\n",
    "checked_file = []\n",
    "\n",
    "\n",
    "for check_date in check_date_list:\n",
    "    for file in 사용자정의채널:\n",
    "        if check_date + '_' + check_date in file:\n",
    "            checked_file.append(file)\n",
    "\n",
    "checked_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 전처리를 한다.\n",
    "\n",
    "for file in checked_file:\n",
    "    df = pd.read_excel(root_path + '/' + file)\n",
    "    df['날짜'] = file[8:18]\n",
    "    col_order = df.columns.to_list()[-1:] + df.columns.to_list()[0:-1]\n",
    "    df = df[col_order]\n",
    "    df.to_csv(root_path + '/dataSub/사용자정의채널/' + file[:-5] + '.csv', encoding='cp949', index=False)\n",
    "    os.remove(root_path + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/사용자정의채널/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "for file in preprocessed_file:\n",
    "    df = pd.read_csv(root_path + '/dataSub/사용자정의채널/' + file, encoding='cp949')\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"Naver_Custom_Order\" (yymmdd, device, nt_source, nt_medium, nt_detail, nt_keyword, customer_cnt, inflow_cnt, page_cnt, page_inflow_cnt, order_cnt, order_inflow_per, order_price, order_inflow_price, contribute_cnt, contribute_inflow_per, contribute_price, contribute_inflow_price) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "\n",
    "\n",
    "    shutil.move(root_path + '/dataSub/사용자정의채널/' + file, root_path + '/dataSub/사용자정의채널/DB입력완료')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검색채널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['검색채널_2023-08-31_2023-08-31.xlsx',\n",
       " '검색채널_2023-09-01_2023-09-01.xlsx',\n",
       " '검색채널_2023-09-02_2023-09-02.xlsx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 파일명에 '검색채널'이 들어간 파일을 읽는다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "검색채널 = [file for file in file_list if '검색채널' in file]\n",
    "\n",
    "검색채널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['검색채널_2023-08-31_2023-08-31.xlsx',\n",
       " '검색채널_2023-09-01_2023-09-01.xlsx',\n",
       " '검색채널_2023-09-02_2023-09-02.xlsx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 유효성 검사를 한다.\n",
    "\n",
    "checked_file = []\n",
    "\n",
    "for check_date in check_date_list:\n",
    "    for file in 검색채널:\n",
    "        if check_date + '_' + check_date in file:\n",
    "            checked_file.append(file)\n",
    "\n",
    "checked_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# 3. 전처리를 한다.\n",
    "\n",
    "for file in checked_file:\n",
    "    df = pd.read_excel(root_path + '/' + file)\n",
    "    df['날짜'] = file[5:15]\n",
    "    df.to_csv(root_path + '/dataSub/검색채널/' + file[:-5] + '.csv', encoding='cp949', index=False)\n",
    "    os.remove(root_path + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/검색채널/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "for file in preprocessed_file:\n",
    "    df = pd.read_csv(root_path + '/dataSub/검색채널/' + file, encoding='cp949')\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"Naver_Search_Channel\" (\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"yymmdd\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "\n",
    "\n",
    "    shutil.move(root_path + '/dataSub/검색채널/' + file, root_path + '/dataSub/검색채널/DB입력완료')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쿠팡광고_본계정_상품광고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파일명에 'A00197911_pa_daily_keyword'이 들어간 파일을 읽는다.\n",
    "# 2. 유효성 검사를 한다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "쿠팡광고_본계정_상품광고 = [file for file in file_list if 'A00197911_pa_daily_keyword' in file]\n",
    "\n",
    "if (len(쿠팡광고_본계정_상품광고) == 1) and ('A00197911_pa_daily_keyword' + '_' + min(check_date_list).replace('-', '') + '_' + max(check_date_list).replace('-', '') in 쿠팡광고_본계정_상품광고[0]):\n",
    "    checked_file = 쿠팡광고_본계정_상품광고[0]\n",
    "    print('유효성 검사 통과')\n",
    "\n",
    "else:\n",
    "    print('오류 발생. 확인해보세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 전처리를 한다.\n",
    "\n",
    "df = pd.read_excel(root_path + '/' + checked_file)\n",
    "df['reg_date'] =df['날짜'].astype(str)\n",
    "df['reg_date'] = df['reg_date'].apply(lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])\n",
    "df['account'] = 'A00197911'\n",
    "df = df.fillna('')\n",
    "\n",
    "numeric_cols = ['총광고수익률(1일)', '직접광고수익률(1일)', '간접광고수익률(1일)', '총광고수익률(14일)', '직접광고수익률(14일)', '간접광고수익률(14일)']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col].str.rstrip('%'))\n",
    "\n",
    "df = df.loc[:, [col for col in df.columns if col != '캠페인 ID']]\n",
    "\n",
    "\n",
    "df.to_csv(root_path + '/dataSub/쿠팡광고_본계정_상품광고/' + checked_file[0:-4] + '.csv', encoding='cp949', index=False)\n",
    "os.remove(root_path + '/' + checked_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/쿠팡광고_본계정_상품광고/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == 1:\n",
    "    df = pd.read_csv(root_path + '/dataSub/쿠팡광고_본계정_상품광고/' + preprocessed_file[0], encoding='cp949', keep_default_na=False)\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"AD_Coupang\" (\"A\", \"B\", \"sales_type\", \"ad_type\", \"campaign\", \"ad_group\", \"product1\", \"product1_id\", \"product2\", \"product2_id\", \"adspace\", \"keyword\", \"impressions\", \"clicks\", \"adcost\", \"clickrate\", \"order_cnt\", \"R\", \"S\", \"out_qty\", \"U\", \"V\", \"gross\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"AC\", \"AD\", \"AE\", \"AF\", \"AG\", \"AH\", \"AI\", \"AJ\", \"AK\", \"AL\", \"AM\", \"AN\", \"AO\", \"AP\", \"reg_date\", \"account\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "        \n",
    "\n",
    "    shutil.move(root_path + '/dataSub/쿠팡광고_본계정_상품광고/' + preprocessed_file[0], root_path + '/dataSub/쿠팡광고_본계정_상품광고/DB입력완료/' + preprocessed_file[0])\n",
    "\n",
    "else:\n",
    "    print('파일 : ' + str(preprocessed_file))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쿠팡광고_본계정_브랜드광고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파일명에 'A00197911_ba_daily_creative'이 들어간 파일을 읽는다.\n",
    "# 2. 유효성 검사를 한다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "쿠팡광고_본계정_브랜드광고 = [file for file in file_list if 'A00197911_ba_daily_creative' in file]\n",
    "\n",
    "\n",
    "if (len(쿠팡광고_본계정_브랜드광고) == 1) and ('A00197911_ba_daily_creative' + '_' + min(check_date_list).replace('-', '') + '_' + max(check_date_list).replace('-', '') in 쿠팡광고_본계정_브랜드광고[0]):\n",
    "    checked_file = 쿠팡광고_본계정_브랜드광고[0]\n",
    "    print('유효성 검사 통과')\n",
    "\n",
    "else:\n",
    "    print('오류 발생. 확인해보세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 전처리를 한다.\n",
    "\n",
    "df = pd.read_excel(root_path + '/' + checked_file)\n",
    "df['reg_date'] =df['날짜'].astype(str)\n",
    "df['reg_date'] = df['reg_date'].apply(lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])\n",
    "df['account'] = 'A00197911'\n",
    "df = df.fillna('')\n",
    "\n",
    "numeric_cols = ['총광고수익률(1일)', '직접광고수익률(1일)', '간접광고수익률(1일)', '총광고수익률(14일)', '직접광고수익률(14일)', '간접광고수익률(14일)']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col].str.rstrip('%'))\n",
    "\n",
    "df = df.loc[:, [col for col in df.columns if col != '입찰유형']]\n",
    "\n",
    "\n",
    "df.to_csv(root_path + '/dataSub/쿠팡광고_본계정_브랜드광고/' + checked_file[0:-4] + '.csv', encoding='cp949', index=False)\n",
    "os.remove(root_path + '/' + checked_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/쿠팡광고_본계정_브랜드광고/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == 1:\n",
    "    df = pd.read_csv(root_path + '/dataSub/쿠팡광고_본계정_브랜드광고/' + preprocessed_file[0], encoding='cp949', keep_default_na=False)\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"AD_CoupangBrand\" (\"A\", \"B\", \"C\", \"D\", \"E\", \"campaign\", \"campaign_id\", \"ad_group\", \"group_id\", \"J\", \"template_type\", \"ad_id\", \"impressions_type\", \"source_type\", \"source\", \"source_id\", \"product\", \"option_id\", \"product2\", \"product2_id\", \"lp_type\", \"lp_name\", \"lp_id\", \"impression_keyword\", \"input_keyword\", \"keyword_type\", \"category\", \"impressions\", \"clicks\", \"clickrate\", \"adcost\", \"order_cnt\", \"AG\", \"AH\", \"out_qty\", \"AJ\", \"AK\", \"gross\", \"AM\", \"AN\", \"AO\", \"AP\", \"AQ\", \"AR\", \"AS\", \"AT\", \"AU\", \"AV\", \"AW\", \"AX\", \"AY\", \"AZ\", \"BA\", \"BB\", \"BC\", \"reg_date\", \"account\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "        \n",
    "\n",
    "    shutil.move(root_path + '/dataSub/쿠팡광고_본계정_브랜드광고/' + preprocessed_file[0], root_path + '/dataSub/쿠팡광고_본계정_브랜드광고/DB입력완료/' + preprocessed_file[0])\n",
    "\n",
    "else:\n",
    "    print('파일 : ' + str(preprocessed_file))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쿠팡광고_서브계정_상품광고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파일명에 'A00350733_pa_daily_keyword'이 들어간 파일을 읽는다.\n",
    "# 2. 유효성 검사를 한다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "쿠팡광고_서브계정_상품광고 = [file for file in file_list if 'A00350733_pa_daily_keyword' in file]\n",
    "\n",
    "if (len(쿠팡광고_서브계정_상품광고) == 1) and ('A00350733_pa_daily_keyword' + '_' + min(check_date_list).replace('-', '') + '_' + max(check_date_list).replace('-', '') in 쿠팡광고_서브계정_상품광고[0]):\n",
    "    checked_file = 쿠팡광고_서브계정_상품광고[0]\n",
    "    print('유효성 검사 통과')\n",
    "\n",
    "else:\n",
    "    print('오류 발생. 확인해보세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 전처리를 한다.\n",
    "\n",
    "df = pd.read_excel(root_path + '/' + checked_file)\n",
    "df['reg_date'] =df['날짜'].astype(str)\n",
    "df['reg_date'] = df['reg_date'].apply(lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])\n",
    "df['account'] = 'A00350733'\n",
    "df = df.fillna('')\n",
    "\n",
    "numeric_cols = ['총광고수익률(1일)', '직접광고수익률(1일)', '간접광고수익률(1일)', '총광고수익률(14일)', '직접광고수익률(14일)', '간접광고수익률(14일)']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col].str.rstrip('%'))\n",
    "\n",
    "df = df.loc[:, [col for col in df.columns if col != '캠페인 ID']]\n",
    "\n",
    "\n",
    "df.to_csv(root_path + '/dataSub/쿠팡광고_서브계정_상품광고/' + checked_file[0:-4] + '.csv', encoding='cp949', index=False)\n",
    "os.remove(root_path + '/' + checked_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/쿠팡광고_서브계정_상품광고/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == 1:\n",
    "    df = pd.read_csv(root_path + '/dataSub/쿠팡광고_서브계정_상품광고/' + preprocessed_file[0], encoding='cp949', keep_default_na=False)\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"AD_Coupang\" (\"A\", \"B\", \"sales_type\", \"ad_type\", \"campaign\", \"ad_group\", \"product1\", \"product1_id\", \"product2\", \"product2_id\", \"adspace\", \"keyword\", \"impressions\", \"clicks\", \"adcost\", \"clickrate\", \"order_cnt\", \"R\", \"S\", \"out_qty\", \"U\", \"V\", \"gross\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"AC\", \"AD\", \"AE\", \"AF\", \"AG\", \"AH\", \"AI\", \"AJ\", \"AK\", \"AL\", \"AM\", \"AN\", \"AO\", \"AP\", \"reg_date\", \"account\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "        \n",
    "\n",
    "    shutil.move(root_path + '/dataSub/쿠팡광고_서브계정_상품광고/' + preprocessed_file[0], root_path + '/dataSub/쿠팡광고_서브계정_상품광고/DB입력완료/' + preprocessed_file[0])\n",
    "\n",
    "else:\n",
    "    print('파일 : ' + str(preprocessed_file))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쿠팡판매통계 (본계정, 서브계정))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파일명에 'Statistics'이 들어간 파일을 읽는다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "쿠팡판매통계 = [file for file in file_list if 'Statistics' in file]\n",
    "\n",
    "쿠팡판매통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 유효성 검사를 한다.\n",
    "# 3. 전처리를 한다.\n",
    "\n",
    "\n",
    "checked_file_dict = {key: [] for key in check_date_list}\n",
    "\n",
    "for check_date in check_date_list:\n",
    "    for file in 쿠팡판매통계:\n",
    "        if check_date.replace('-', '') + '~' + check_date.replace('-', '') in file:\n",
    "            checked_file_dict[check_date].append(file)\n",
    "\n",
    "\n",
    "for check_date in check_date_list:\n",
    "    df1 = pd.read_excel(root_path + '/' + checked_file_dict[check_date][0], dtype={'노출상품ID':object, '옵션ID':object})\n",
    "    df2 = pd.read_excel(root_path + '/' + checked_file_dict[check_date][1], dtype={'노출상품ID':object, '옵션ID':object})\n",
    "    df1['날짜'] = check_date\n",
    "    df2['날짜'] = check_date\n",
    "    if df1.iloc[-1, 6] > df2.iloc[-1, 6]:\n",
    "        df1['계정'] = 'A00197911'\n",
    "        df2['계정'] = 'A00350733'\n",
    "        df1.to_csv(root_path + '/dataSub/쿠팡판매통계_본계정/' + checked_file_dict[check_date][0][:-5] + '.csv', encoding='cp949', index=False)\n",
    "        df2.to_csv(root_path + '/dataSub/쿠팡판매통계_서브계정/' + checked_file_dict[check_date][1][:-5] + '.csv', encoding='cp949', index=False)\n",
    "    else:\n",
    "        df1['계정'] = 'A00350733'\n",
    "        df2['계정'] = 'A00197911'\n",
    "        df1.to_csv(root_path + '/dataSub/쿠팡판매통계_서브계정/' + checked_file_dict[check_date][0][:-5] + '.csv', encoding='cp949', index=False)\n",
    "        df2.to_csv(root_path + '/dataSub/쿠팡판매통계_본계정/' + checked_file_dict[check_date][1][:-5] + '.csv', encoding='cp949', index=False)\n",
    "    os.remove(root_path + '/' + checked_file_dict[check_date][0])\n",
    "    os.remove(root_path + '/' + checked_file_dict[check_date][1])\n",
    "\n",
    "print('유효성 검사 및 전처리 완료')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1. db에 입력한다.\n",
    "# 쿠팡판매통계_본계정\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/쿠팡판매통계_본계정/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == len(check_date_list):\n",
    "    for file in preprocessed_file:\n",
    "        df = pd.read_csv(root_path + '/dataSub/쿠팡판매통계_본계정/' + file, encoding='cp949', skipfooter=1, keep_default_na=False)\n",
    "        data = df.values.tolist()\n",
    "        for d in data:\n",
    "            cursor.execute('INSERT INTO \"coupang_sales\" (\"product_id\", \"option_id\", \"option_name\", \"sales_type\", \"category\", \"item_winner_ratio\", \"net_sales_price\", \"net_sales_cnt\", \"sales_price\", \"sales_cnt\", \"cancel_price\", \"cancel_cnt\", \"instant_cancel_cnt\", \"reg_date\", \"account\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "            \n",
    "\n",
    "        shutil.move(root_path + '/dataSub/쿠팡판매통계_본계정/' + file, root_path + '/dataSub/쿠팡판매통계_본계정/DB입력완료')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-2. db에 입력한다.\n",
    "# 쿠팡판매통계_서브계정\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/쿠팡판매통계_서브계정/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == len(check_date_list):\n",
    "    for file in preprocessed_file:\n",
    "        df = pd.read_csv(root_path + '/dataSub/쿠팡판매통계_서브계정/' + file, encoding='cp949', skipfooter=1, keep_default_na=False)\n",
    "        data = df.values.tolist()\n",
    "        for d in data:\n",
    "            cursor.execute('INSERT INTO \"coupang_sales\" (\"product_id\", \"option_id\", \"option_name\", \"sales_type\", \"category\", \"item_winner_ratio\", \"net_sales_price\", \"net_sales_cnt\", \"sales_price\", \"sales_cnt\", \"cancel_price\", \"cancel_cnt\", \"instant_cancel_cnt\", \"reg_date\", \"account\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "            \n",
    "\n",
    "        shutil.move(root_path + '/dataSub/쿠팡판매통계_서브계정/' + file, root_path + '/dataSub/쿠팡판매통계_서브계정/DB입력완료')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메타_자사계정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADN광고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파일명에 '일별_캠페인_그룹_소재_포함_실적_보고서'이 들어간 파일을 읽는다.\n",
    "\n",
    "root_path = 'C:/dataHub'\n",
    "file_list = os.listdir(root_path)\n",
    "\n",
    "ADN광고 = [file for file in file_list if '일별_캠페인_그룹_소재_포함_실적_보고서' in file]\n",
    "\n",
    "ADN광고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 유효성 검사를 한다.\n",
    "# 3. 전처리를 한다.\n",
    "\n",
    "if  len(ADN광고) == 1:\n",
    "\n",
    "    df = pd.read_excel(root_path + '/' + ADN광고[0], thousands = ',')\n",
    "    df.drop(0, inplace=True) \n",
    "\n",
    "    날짜 = sorted(df['날짜'].apply(lambda x: x[0:-3]).unique().tolist())\n",
    "    \n",
    "    if 날짜 == sorted(check_date_list):\n",
    "        df.to_csv(root_path + '/dataSub/ADN광고/' + ADN광고[0][0:-5] + '.csv', encoding='cp949', index=False)\n",
    "        os.remove(root_path + '/' + ADN광고[0])\n",
    "        print('유효성 검사 및 전처리 완료')\n",
    "\n",
    "    else:\n",
    "        print('실행안됨 : 날짜가 맞지 않습니다.')\n",
    "else:\n",
    "    print('실행안됨 : dataHub에 파일이 없습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. db에 입력한다.\n",
    "\n",
    "conn = psycopg2.connect(host='115.68.228.168', user='postgres', password='cldngks', dbname='phytogether', port=5432)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "preprocessed_file = os.listdir(root_path + '/dataSub/ADN광고/')\n",
    "preprocessed_file.remove('DB입력완료')\n",
    "\n",
    "\n",
    "if len(preprocessed_file) == 1:\n",
    "    df = pd.read_csv(root_path + '/dataSub/ADN광고/' + preprocessed_file[0], encoding='cp949', keep_default_na=False)\n",
    "    data = df.values.tolist()\n",
    "    for d in data:\n",
    "        cursor.execute('INSERT INTO \"ad_adn\" (\"date\", \"campaign\", \"adgroup\", \"ad\", \"impression\", \"click\", \"click_rate\", \"cpc\", \"order_cnt\", \"conversion_rate\", \"adcost\", \"gross\", \"order_direct\", \"gross_direct\", \"order_indirect\", \"gross_indirect\", \"order_npay_direct\", \"gross_npay_diect\", \"order_npay_indirect\", \"gross_npay_indirect\", \"roas\", \"db\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)', d)\n",
    "\n",
    "\n",
    "    shutil.move(root_path + '/dataSub/ADN광고/' + preprocessed_file[0], root_path + '/dataSub/ADN광고/DB입력완료/' + preprocessed_file[0][0:-5] + '_' + min(check_date_list) + '~' + max(check_date_list) + '.csv')\n",
    "\n",
    "else:\n",
    "    print('파일 : ' + str(preprocessed_file))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
